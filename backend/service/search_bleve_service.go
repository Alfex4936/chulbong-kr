package service

import (
	"context"
	"fmt"
	"log"
	"runtime"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"
	"unicode"

	"github.com/Alfex4936/chulbong-kr/dto"
	"github.com/Alfex4936/dkssud"
	"github.com/blevesearch/bleve/v2"
	bleve_search "github.com/blevesearch/bleve/v2/search"
	"github.com/blevesearch/bleve/v2/search/query"
	"go.uber.org/zap"

	gocache "github.com/eko/gocache/lib/v4/cache"
	ristretto_store "github.com/eko/gocache/store/ristretto/v4"
)

// Map of Hangul initial consonant Unicode values to their corresponding Korean consonants.
var (
	initialConsonantMap = map[rune]rune{
		0x1100: 'ã„±', 0x1101: 'ã„²', 0x1102: 'ã„´', 0x1103: 'ã„·', 0x1104: 'ã„¸',
		0x1105: 'ã„¹', 0x1106: 'ã…', 0x1107: 'ã…‚', 0x1108: 'ã…ƒ', 0x1109: 'ã……',
		0x110A: 'ã…†', 0x110B: 'ã…‡', 0x110C: 'ã…ˆ', 0x110D: 'ã…‰', 0x110E: 'ã…Š',
		0x110F: 'ã…‹', 0x1110: 'ã…Œ', 0x1111: 'ã…', 0x1112: 'ã…',
	}

	validInitialConsonants = map[rune]bool{
		'ã„±': true, 'ã„²': true, 'ã„´': true, 'ã„·': true, 'ã„¸': true,
		'ã„¹': true, 'ã…': true, 'ã…‚': true, 'ã…ƒ': true, 'ã……': true,
		'ã…†': true, 'ã…‡': true, 'ã…ˆ': true, 'ã…‰': true, 'ã…Š': true,
		'ã…‹': true, 'ã…Œ': true, 'ã…': true, 'ã…': true,
	}

	doubleConsonants = map[rune][]rune{
		'ã„³': {'ã„±', 'ã……'}, 'ã„µ': {'ã„´', 'ã…ˆ'}, 'ã„¶': {'ã„´', 'ã…'}, 'ã„º': {'ã„¹', 'ã„±'},
		'ã„»': {'ã„¹', 'ã…'}, 'ã„¼': {'ã„¹', 'ã…‚'}, 'ã„½': {'ã„¹', 'ã……'}, 'ã„¾': {'ã„¹', 'ã…Œ'},
		'ã„¿': {'ã„¹', 'ã…'}, 'ã…€': {'ã„¹', 'ã…'}, 'ã…„': {'ã…‚', 'ã……'},
	}

	documentMatchPool = &sync.Pool{
		New: func() any {
			slice := make([]*bleve_search.DocumentMatch, 0, 100)
			return &slice
		},
	}

	termsPool = &sync.Pool{
		New: func() any {
			slice := make([]string, 0, 30)
			return &slice
		},
	}
)

type BleveSearchService struct {
	Index  bleve.Index
	Shards []bleve.Index

	LocalCacheStorage *ristretto_store.RistrettoStore
	Logger            *zap.Logger
	// Path string

	searchCache *gocache.Cache[dto.MarkerSearchResponse]
}

func NewBleveSearchService(
	index bleve.Index, shards []bleve.Index,
	localCacheStorage *ristretto_store.RistrettoStore, logger *zap.Logger) *BleveSearchService {
	searchCache := gocache.New[dto.MarkerSearchResponse](localCacheStorage)

	return &BleveSearchService{Index: index, Shards: shards, searchCache: searchCache, Logger: logger}
}

// SearchMarkerAddress calls bleve (Lucene-like) search
// func (s *BleveSearchService) SearchMarkerAddress(term string) (dto.MarkerSearchResponse, error) {
// 	var response dto.MarkerSearchResponse
// 	searchQuery := bleve.NewFuzzyQuery(term)
// 	searchRequest := bleve.NewSearchRequest(searchQuery)
// 	searchRequest.From = 0
// 	searchRequest.Size = 10
// 	searchRequest.Fields = []string{"address"} // or *

// 	searchResults, err := s.Index.Search(searchRequest)
// 	if err != nil {
// 		return response, fmt.Errorf("error searching index")
// 	}

// 	response = MarkerSearchResponse{
// 		Took:    int(searchResults.Took.Milliseconds()),
// 		Markers: make([]dto.ZincMarker, 0, len(searchResults.Hits)),
// 	}

// 	// Extract relevant fields from search results
// 	for _, hit := range searchResults.Hits {
// 		var marker dto.ZincMarker
// 		intID, _ := strconv.Atoi(hit.ID)
// 		marker.MarkerID = intID
// 		marker.Address = hit.Fields["address"].(string)
// 		response.Markers = append(response.Markers, marker)
// 	}

// 	return response, nil
// }

// SearchMarkerAddress calls bleve (Lucene-like) search
func (s *BleveSearchService) SearchMarkerAddress(t string) (dto.MarkerSearchResponse, error) {
	// t is already trimmed
	cacheKey := fmt.Sprintf("search:%s", t)
	cachedResponse, err := s.searchCache.Get(context.Background(), cacheKey)
	if err == nil {
		return cachedResponse, nil
	}

	// ì¿¼í‹° í•œê¸€? -> í•œê¸€ë¡œ ë³€í™˜ (ex. "rudrleh" -> "ê²½ê¸°ë„")
	if dkssud.IsQwertyHangul(t) {
		t = dkssud.QwertyToHangul(t)
	}

	response := dto.MarkerSearchResponse{Markers: make([]dto.ZincMarker, 0)}

	// Get a pointer to a slice from the pool
	termsPtr := termsPool.Get().(*[]string)
	terms := (*termsPtr)[:0] // Reset the slice

	// Split the search term by spaces and append to the pooled slice
	terms = append(terms, strings.Fields(t)...)
	if len(terms) == 0 {
		termsPool.Put(termsPtr)
		return response, nil
	}

	terms[0] = standardizeInitials(terms[0])

	results := make(chan *bleve_search.DocumentMatch, len(terms)*10)
	tookTimes := make(chan time.Duration, len(terms))
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	var wg sync.WaitGroup
	termChan := make(chan string, len(terms))

	// -- Use runtime.GOMAXPROCS(0) to determine the number of workers
	workerCount := runtime.NumCPU() // Limit goroutines to number of CPU cores
	for i := 0; i < workerCount; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for term := range termChan {
				select {
				case <-ctx.Done():
					return
				default:
					performSearch(s.Index, term, results, tookTimes)
				}
			}
		}()
	}

	for _, term := range terms {
		termChan <- term
	}
	close(termChan)

	go func() {
		wg.Wait()
		close(results)
		close(tookTimes)
	}()

	// Get a pointer to a slice from the pool
	allResultsPtr := documentMatchPool.Get().(*[]*bleve_search.DocumentMatch)
	allResults := (*allResultsPtr)[:0] // Reset the slice
	var totalTook time.Duration

	for {
		select {
		case result, ok := <-results:
			if !ok {
				results = nil
			} else if result != nil {
				allResults = append(allResults, result)
			}
		case took, ok := <-tookTimes:
			if !ok {
				tookTimes = nil
			} else {
				totalTook += took
			}
		}

		if results == nil && tookTimes == nil {
			break
		}
	}

	// Sort and ensure diverse results
	// diverseResults := ensureDiversity(allResults, 10)

	if len(allResults) == 0 {
		// If no results, try fuzzy search with controlled fuzziness
		fuzzyResults, fuzzyTook := performFuzzySearch(s.Index, terms)
		allResults = fuzzyResults
		totalTook += fuzzyTook
	}

	sortResultsByScore(allResults)
	response.Took = int(totalTook.Milliseconds())
	response.Markers = extractMarkers(allResults)

	// Cache the response
	s.searchCache.Set(context.Background(), cacheKey, response)

	// Reset the slice and return the pointer to the pool
	*allResultsPtr = allResults[:0]
	documentMatchPool.Put(allResultsPtr)

	// Return terms slice to the pool
	*termsPtr = terms[:0]
	termsPool.Put(termsPtr)

	return response, nil
}

func (s *BleveSearchService) AutoComplete(term string) ([]string, error) {
	var suggestions []string

	prefixQuery := bleve.NewPrefixQuery(term)
	searchRequest := bleve.NewSearchRequest(prefixQuery)
	searchRequest.Fields = []string{"fullAddress", "address", "province", "city"}
	searchRequest.Size = 10 // Limit the number of suggestions

	searchResult, err := s.Index.Search(searchRequest)
	if err != nil {
		return nil, fmt.Errorf("error performing autocomplete search: %v", err)
	}

	for _, hit := range searchResult.Hits {
		suggestions = append(suggestions, hit.Fields["fullAddress"].(string))
	}

	return suggestions, nil
}

func (s *BleveSearchService) InsertMarkerIndex(indexBody MarkerIndexData) error {
	defer s.Logger.Info("InsertMarkerIndex called", zap.Int("markerID", indexBody.MarkerID))

	// Compute which shard to use based on the marker ID (or any other key)
	shardIndex := indexBody.MarkerID % len(s.Shards)
	selectedShard := s.Shards[shardIndex]

	province, city, rest := splitAddress(indexBody.Address)
	indexBody.Province = province
	indexBody.City = city
	indexBody.FullAddress = indexBody.Address
	indexBody.Address = rest
	indexBody.InitialConsonants = ExtractInitialConsonants(indexBody.FullAddress)

	err := selectedShard.Index(strconv.Itoa(indexBody.MarkerID), indexBody)
	if err != nil {
		return fmt.Errorf("error indexing marker: %v", err)
	}

	// Invalidate search cache
	s.invalidateCache()

	defer s.Logger.Info("ğŸ” [DEBUG] InsertMarkerIndex worked?", zap.String("addr", indexBody.FullAddress))

	return nil
}

func (s *BleveSearchService) DeleteMarkerIndex(markerId int) error {
	// Compute which shard to use based on the marker ID (same as in InsertMarkerIndex)
	shardIndex := markerId % len(s.Shards)
	selectedShard := s.Shards[shardIndex]

	// Perform the deletion operation on the selected shard
	err := selectedShard.Delete(strconv.Itoa(markerId))
	if err != nil {
		return fmt.Errorf("error deleting marker: %v", err)
	}

	// Invalidate search cache
	s.invalidateCache()

	return nil
}

func (s *BleveSearchService) invalidateCache() {
	s.searchCache.Clear(context.Background())
}

func performSearch(index bleve.Index, term string, results chan<- *bleve_search.DocumentMatch, tookTimes chan<- time.Duration) {
	var queries []query.Query
	const analyzer = "koCJKEdgeNgram"

	// Use a buffer pool for reduced allocations
	bufferPool := sync.Pool{
		New: func() interface{} {
			b := make([]byte, 0, 256) // Increased initial capacity
			return &b
		},
	}

	bufferPtr := bufferPool.Get().(*[]byte)
	defer bufferPool.Put(bufferPtr)
	buffer := (*bufferPtr)[:0]

	// Helper function to reset and reuse the buffer
	resetBuffer := func() {
		buffer = buffer[:0]
	}

	// Helper function to append string to buffer and get string back
	appendString := func(s string) string {
		resetBuffer()
		buffer = append(buffer, s...)
		return string(buffer)
	}

	// Exact match queries with higher boosts
	matchQueryFullAddress := query.NewMatchQuery(appendString(term))
	matchQueryFullAddress.SetField("fullAddress")
	matchQueryFullAddress.Analyzer = analyzer
	matchQueryFullAddress.SetBoost(25.0)
	queries = append(queries, matchQueryFullAddress)

	// Phrase match query for exact phrases
	matchPhraseQueryFullAddress := query.NewMatchPhraseQuery(appendString(term))
	matchPhraseQueryFullAddress.SetField("fullAddress")
	matchPhraseQueryFullAddress.Analyzer = analyzer
	matchPhraseQueryFullAddress.SetBoost(20.0)
	queries = append(queries, matchPhraseQueryFullAddress)

	// Wildcard queries with lower boosts
	resetBuffer()
	buffer = append(buffer, '*')
	buffer = append(buffer, term...)
	buffer = append(buffer, '*')
	wildcardQueryFullAddress := query.NewWildcardQuery(string(buffer))
	wildcardQueryFullAddress.SetField("fullAddress")
	wildcardQueryFullAddress.SetBoost(15.0)
	queries = append(queries, wildcardQueryFullAddress)

	prefixQueryFullAddress := query.NewPrefixQuery(appendString(term))
	prefixQueryFullAddress.SetField("fullAddress")
	prefixQueryFullAddress.SetBoost(35.0)
	queries = append(queries, prefixQueryFullAddress)

	// Additional fields and queries
	brokenConsonants := appendString(SegmentConsonants(term))
	matchQueryInitialConsonants := query.NewMatchQuery(brokenConsonants)
	matchQueryInitialConsonants.SetField("initialConsonants")
	matchQueryInitialConsonants.Analyzer = analyzer
	matchQueryInitialConsonants.SetBoost(15.0)
	queries = append(queries, matchQueryInitialConsonants)

	resetBuffer()
	buffer = append(buffer, '*')
	buffer = append(buffer, brokenConsonants...)
	buffer = append(buffer, '*')
	wildcardQueryInitialConsonants := query.NewWildcardQuery(string(buffer))
	wildcardQueryInitialConsonants.SetField("initialConsonants")
	wildcardQueryInitialConsonants.SetBoost(7.0)
	queries = append(queries, wildcardQueryInitialConsonants)

	prefixQueryInitialConsonants := query.NewPrefixQuery(appendString(brokenConsonants))
	prefixQueryInitialConsonants.SetField("initialConsonants")
	prefixQueryInitialConsonants.SetBoost(25.0)
	queries = append(queries, prefixQueryInitialConsonants)

	standardizedProvince := appendString(standardizeProvince(term))
	if standardizedProvince != term {
		matchQueryProvince := query.NewPrefixQuery(standardizedProvince)
		matchQueryProvince.SetField("province")
		matchQueryProvince.SetBoost(3.0)
		queries = append(queries, matchQueryProvince)
	} else {
		prefixQueryCity := query.NewPrefixQuery(appendString(term))
		prefixQueryCity.SetField("city")
		prefixQueryCity.SetBoost(10.0)
		queries = append(queries, prefixQueryCity)

		matchQueryCity := query.NewMatchQuery(appendString(term))
		matchQueryCity.SetField("city")
		matchQueryCity.Analyzer = analyzer
		matchQueryCity.SetBoost(10.0)
		queries = append(queries, matchQueryCity)

		matchQueryDistrict := query.NewMatchQuery(appendString(term))
		matchQueryDistrict.SetField("district")
		matchQueryDistrict.Analyzer = analyzer
		matchQueryDistrict.SetBoost(5.0)
		queries = append(queries, matchQueryDistrict)

		prefixQueryAddr := query.NewPrefixQuery(appendString(term))
		prefixQueryAddr.SetField("address")
		prefixQueryAddr.SetBoost(10.0)
		queries = append(queries, prefixQueryAddr)

		resetBuffer()
		buffer = append(buffer, '*')
		buffer = append(buffer, term...)
		buffer = append(buffer, '*')
		wildcardQueryAddr := query.NewWildcardQuery(string(buffer))
		wildcardQueryAddr.SetField("address")
		wildcardQueryAddr.SetBoost(5.0)
		queries = append(queries, wildcardQueryAddr)
	}

	disjunctionQuery := bleve.NewDisjunctionQuery(queries...)
	searchRequest := bleve.NewSearchRequestOptions(disjunctionQuery, 15, 0, false)
	searchRequest.Fields = []string{"fullAddress", "address", "province", "city", "initialConsonants"}
	searchRequest.Size = 10
	searchRequest.Highlight = bleve.NewHighlightWithStyle("html")
	searchRequest.SortBy([]string{"_score", "markerId"})

	searchResult, err := index.Search(searchRequest)
	if err != nil {
		return
	}

	tookTimes <- searchResult.Took
	for _, hit := range searchResult.Hits {
		results <- hit
	}
}

// Perform search with facets
func performSearchFacet(index bleve.Index, term string, results chan<- *bleve_search.DocumentMatch, tookTimes chan<- time.Duration) {
	var queries []query.Query

	// Exact match queries with higher boosts
	matchQueryFullAddress := query.NewMatchQuery(term)
	matchQueryFullAddress.SetField("fullAddress")
	matchQueryFullAddress.Analyzer = "koCJKEdgeNgram"
	matchQueryFullAddress.SetBoost(25.0)
	queries = append(queries, matchQueryFullAddress)

	// Phrase match query for exact phrases
	matchPhraseQueryFullAddress := query.NewMatchPhraseQuery(term)
	matchPhraseQueryFullAddress.SetField("fullAddress")
	matchPhraseQueryFullAddress.Analyzer = "koCJKEdgeNgram"
	matchPhraseQueryFullAddress.SetBoost(20.0)
	queries = append(queries, matchPhraseQueryFullAddress)

	// Wildcard queries with lower boosts
	wildcardQueryFullAddress := query.NewWildcardQuery("*" + term + "*")
	wildcardQueryFullAddress.SetField("fullAddress")
	wildcardQueryFullAddress.SetBoost(10.0)
	queries = append(queries, wildcardQueryFullAddress)

	// Additional fields and queries
	brokenConsonants := SegmentConsonants(term)
	matchQueryInitialConsonants := query.NewMatchQuery(brokenConsonants)
	matchQueryInitialConsonants.SetField("initialConsonants")
	matchQueryInitialConsonants.Analyzer = "koCJKEdgeNgram"
	matchQueryInitialConsonants.SetBoost(15.0)
	queries = append(queries, matchQueryInitialConsonants)

	wildcardQueryInitialConsonants := query.NewWildcardQuery("*" + brokenConsonants + "*")
	wildcardQueryInitialConsonants.SetField("initialConsonants")
	wildcardQueryInitialConsonants.SetBoost(5.0)
	queries = append(queries, wildcardQueryInitialConsonants)

	standardizedProvince := standardizeProvince(term)
	if standardizedProvince != term {
		matchQueryProvince := query.NewMatchQuery(standardizedProvince)
		matchQueryProvince.SetField("province")
		matchQueryProvince.Analyzer = "koCJKEdgeNgram"
		matchQueryProvince.SetBoost(1.5)
		queries = append(queries, matchQueryProvince)
	} else {
		prefixQueryCity := query.NewPrefixQuery(term)
		prefixQueryCity.SetField("city")
		prefixQueryCity.SetBoost(10.0)
		queries = append(queries, prefixQueryCity)

		matchQueryCity := query.NewMatchQuery(term)
		matchQueryCity.SetField("city")
		matchQueryCity.Analyzer = "koCJKEdgeNgram"
		matchQueryCity.SetBoost(10.0)
		queries = append(queries, matchQueryCity)

		matchQueryDistrict := query.NewMatchQuery(term)
		matchQueryDistrict.SetField("district")
		matchQueryDistrict.Analyzer = "koCJKEdgeNgram"
		matchQueryDistrict.SetBoost(5.0)
		queries = append(queries, matchQueryDistrict)

		prefixQueryAddr := query.NewPrefixQuery(term)
		prefixQueryAddr.SetField("address")
		prefixQueryAddr.SetBoost(5.0)
		queries = append(queries, prefixQueryAddr)

		wildcardQueryAddr := query.NewWildcardQuery("*" + term + "*")
		wildcardQueryAddr.SetField("address")
		wildcardQueryAddr.SetBoost(2.0)
		queries = append(queries, wildcardQueryAddr)
	}

	disjunctionQuery := bleve.NewDisjunctionQuery(queries...)
	searchRequest := bleve.NewSearchRequest(disjunctionQuery)
	searchRequest.Highlight = bleve.NewHighlightWithStyle("html")
	searchRequest.Fields = []string{"fullAddress", "address", "province", "city", "initialConsonants"}
	searchRequest.Size = 10
	searchRequest.SortBy([]string{"_score", "markerId"})

	// Add facet request for province
	facetRequest := bleve.NewFacetRequest("province", 10)
	searchRequest.AddFacet("province_facets", facetRequest)

	searchResult, err := index.Search(searchRequest)
	if err != nil {
		log.Printf("Error performing search: %v", err)
		return
	}

	tookTimes <- searchResult.Took
	for _, hit := range searchResult.Hits {
		results <- hit
	}

	// Print facet results
	if facet, found := searchResult.Facets["province_facets"]; found {
		fmt.Printf("Facet Results for 'province':\n")
		fmt.Printf("Total: %d\n", facet.Total)
		fmt.Printf("Missing: %d\n", facet.Missing)
		for _, term := range facet.Terms.Terms() {
			fmt.Printf("Term: %s, Count: %d\n", term.Term, term.Count)
		}
	}
}

func performFuzzySearch(index bleve.Index, terms []string) ([]*bleve_search.DocumentMatch, time.Duration) {
	var allResults []*bleve_search.DocumentMatch
	var totalTook time.Duration

	for _, term := range terms {
		fuzzyQuery := bleve.NewFuzzyQuery(term)
		fuzzyQuery.Fuzziness = 1
		searchRequest := bleve.NewSearchRequest(fuzzyQuery)
		searchRequest.Fields = []string{"fullAddress", "address", "province", "city", "initialConsonants"}
		searchRequest.Size = 10
		searchRequest.Highlight = bleve.NewHighlightWithStyle("html")
		searchResult, err := index.Search(searchRequest)
		if err != nil {
			log.Printf("Error fuzzy searching marker: %v", err)
			continue
		}
		allResults = append(allResults, searchResult.Hits...)
		totalTook += searchResult.Took
	}

	return allResults, totalTook
}

func extractMarkers(allResults []*bleve_search.DocumentMatch) []dto.ZincMarker {
	markers := make([]dto.ZincMarker, 0, len(allResults))
	for _, hit := range allResults {
		intID, _ := strconv.Atoi(hit.ID)
		markers = append(markers, dto.ZincMarker{
			MarkerID: intID,
			Address:  hit.Fields["fullAddress"].(string),
		})
	}
	return markers
}

// extractInitialConsonants extracts the initial consonants from a Korean string.
//
// ex) "ë¶€ì‚° í•´ìš´ëŒ€êµ¬ ì¢Œë™ 1395" -> "ã…‚ã……ã…ã…‡ã„·ã„±ã…ˆã„·"
func ExtractInitialConsonants(s string) string {
	var initials []rune
	for _, r := range s {
		if unicode.Is(unicode.Hangul, r) {
			initial := (r - 0xAC00) / 28 / 21
			if mapped, exists := initialConsonantMap[0x1100+initial]; exists {
				initials = append(initials, mapped)
			}
		}
	}
	return string(initials)
}

// Split the user input into valid Korean initial consonants, breaking double consonants where necessary
//
// ex) "ì•ëã…„ã„³ì‚°" -> "ì•ëã…‚ã……ã„±ã……ì‚°"
func SegmentConsonants(input string) string {
	var result []rune

	for _, r := range input {
		// Check if the character is a valid initial consonant
		if validInitialConsonants[r] {
			result = append(result, r)
		} else if components, found := doubleConsonants[r]; found {
			// If it's a double consonant, break it into its components
			result = append(result, components...)
		} else {
			// If it's not a valid consonant or double consonant, add it as is
			result = append(result, r)
		}
	}

	return string(result)
}

func standardizeProvince(province string) string {
	switch province {
	case "ê²½ê¸°", "ê²½ê¸°ë„", "ã„±ã„±ã„·":
		return "ê²½ê¸°ë„"
	case "ì„œìš¸", "ì„œìš¸íŠ¹ë³„ì‹œ", "ã……ã…‡", "ã……ã…‡ã…Œã…‚ã……":
		return "ì„œìš¸íŠ¹ë³„ì‹œ"
	case "ë¶€ì‚°", "ë¶€ì‚°ê´‘ì—­ì‹œ", "ã…„":
		return "ë¶€ì‚°ê´‘ì—­ì‹œ"
	case "ëŒ€êµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ", "ã„·ã„±":
		return "ëŒ€êµ¬ê´‘ì—­ì‹œ"
	case "ì¸ì²œ", "ì¸ì²œê´‘ì—­ì‹œ", "ã…‡ã…Š":
		return "ì¸ì²œê´‘ì—­ì‹œ"
	case "ì œì£¼", "ì œì£¼íŠ¹ë³„ìì¹˜ë„", "ì œì£¼ë„", "ã…ˆã…ˆã„·":
		return "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
	case "ëŒ€ì „", "ëŒ€ì „ê´‘ì—­ì‹œ":
		return "ëŒ€ì „ê´‘ì—­ì‹œ"
	case "ìš¸ì‚°", "ìš¸ì‚°ê´‘ì—­ì‹œ":
		return "ìš¸ì‚°ê´‘ì—­ì‹œ"
	case "ê´‘ì£¼", "ê´‘ì£¼ê´‘ì—­ì‹œ":
		return "ê´‘ì£¼ê´‘ì—­ì‹œ"
	case "ì„¸ì¢…", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ":
		return "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ"
	case "ê°•ì›", "ê°•ì›ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„", "ã„±ã…‡ã„·":
		return "ê°•ì›íŠ¹ë³„ìì¹˜ë„"
	case "ê²½ë‚¨", "ê²½ìƒë‚¨ë„":
		return "ê²½ìƒë‚¨ë„"
	case "ê²½ë¶", "ê²½ìƒë¶ë„":
		return "ê²½ìƒë¶ë„"
	case "ì „ë¶", "ì „ë¶íŠ¹ë³„ìì¹˜ë„":
		return "ì „ë¶íŠ¹ë³„ìì¹˜ë„"
	case "ì¶©ë‚¨", "ì¶©ì²­ë‚¨ë„":
		return "ì¶©ì²­ë‚¨ë„"
	case "ì¶©ë¶", "ì¶©ì²­ë¶ë„":
		return "ì¶©ì²­ë¶ë„"
	case "ì „ë‚¨", "ì „ë¼ë‚¨ë„":
		return "ì „ë¼ë‚¨ë„"
	default:
		return province
	}
}

func standardizeInitials(initials string) string {
	switch initials {
	case "ã„±ã„±":
		return "ã„±ã„±ã„·"
	case "ã……ã…‡", "ã……ã…‡ã……":
		return "ã……ã…‡ã…Œã…‚ã……"
	case "ã…„", "ã…„ã……", "ã…‚ã……":
		return "ã…‚ã……ã„±ã…‡ã……"
	case "ã„·ã„±":
		return "ã„·ã„±ã„±ã…‡ã……"
	case "ã…‡ã…Šã……":
		return "ã…‡ã…Šã„±ã…‡ã……"
	case "ã…ˆã…ˆã„·", "ã…ˆã…ˆ":
		return "ã…ˆã…ˆã…Œã…‚ã…ˆã…Šã„·"
	case "ã„·ã…ˆ":
		return "ã„·ã…ˆã„±ã…‡ã……"
	case "ã…‡ã……":
		return "ã…‡ã……ã„±ã…‡ã……"
	case "ã„±ã…ˆ":
		return "ã„±ã…ˆã„±ã…‡ã……"
	case "ã……ã…ˆã……":
		return "ã……ã…ˆã…Œã…‚ã…ˆã…Šã……"
	case "ã„±ã…‡ã„·":
		return "ã„±ã…‡ã…Œã…‚ã…ˆã…Šã„·"
	case "ã„³ã„´ã„·", "ã„±ã……ã„´ã„·":
		return "ã„±ã……ã„´ã„·"
	case "ã„³ã…‚ã„·", "ã„±ã……ã…‚ã„·":
		return "ã„±ã……ã…‚ã„·"
	case "ã…ˆã…‚":
		return "ã…ˆã…‚ã…Œã…‚ã…ˆã…Šã„·"
	case "ã…Šã„´":
		return "ã…Šã…Šã„´ã„·"
	case "ã…Šã…‚":
		return "ã…Šã…Šã…‚ã„·"
	case "ã…ˆã„´":
		return "ã…ˆã„¹ã„´ã„·"
	default:
		return initials
	}
}

func splitAddress(address string) (string, string, string) {
	parts := strings.Fields(address)
	if len(parts) < 2 {
		return "", "", address
	}
	province := standardizeProvince(parts[0])
	city := parts[1]
	rest := strings.Join(parts[2:], " ")
	return province, city, rest
}

func ensureDiversity(results []*bleve_search.DocumentMatch, limit int) []*bleve_search.DocumentMatch {
	addressSet := make(map[string]struct{})
	var diverseResults []*bleve_search.DocumentMatch

	for _, result := range results {
		if len(diverseResults) >= limit {
			break
		}
		address := result.Fields["fullAddress"].(string)
		if _, exists := addressSet[address]; !exists {
			addressSet[address] = struct{}{}
			diverseResults = append(diverseResults, result)
		}
	}

	return diverseResults
}

func sortResultsByScore(results []*bleve_search.DocumentMatch) {
	sort.Slice(results, func(i, j int) bool {
		return results[i].Score > results[j].Score
	})
}
