package main

import (
	"database/sql"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"sort"
	"strconv"
	"strings"
	"sync"
	"time"
	gounicode "unicode"

	"github.com/blevesearch/bleve/v2"
	"github.com/blevesearch/bleve/v2/analysis/analyzer/custom"
	_ "github.com/blevesearch/bleve/v2/analysis/char/html"
	_ "github.com/blevesearch/bleve/v2/analysis/lang/cjk"
	"github.com/blevesearch/bleve/v2/analysis/token/edgengram"
	"github.com/blevesearch/bleve/v2/analysis/token/lowercase"
	_ "github.com/blevesearch/bleve/v2/analysis/token/ngram"
	"github.com/blevesearch/bleve/v2/analysis/token/unicodenorm"
	"github.com/blevesearch/bleve/v2/analysis/tokenizer/unicode"
	_ "github.com/blevesearch/bleve/v2/index/upsidedown/store/boltdb"
	bleve_search "github.com/blevesearch/bleve/v2/search"
	"github.com/blevesearch/bleve/v2/search/highlight/format/html"
	"github.com/blevesearch/bleve/v2/search/query"

	_ "github.com/go-sql-driver/mysql"
	"github.com/joho/godotenv"
)

// MarkerDB represents the structure of the marker data from DB.
type MarkerDB struct {
	MarkerID int    `json:"markerId"`
	Address  string `json:"address"`
}

type Marker struct {
	MarkerID          int    `json:"markerId"`
	Province          string `json:"province"`
	City              string `json:"city"`
	Address           string `json:"address"` // such as Korean: ê²½ê¸°ë„ ë¶€ì²œì‹œ ì†Œì‚¬êµ¬ ê²½ì¸ë¡œ29ë²ˆê¸¸ 32, ìš°ì„±ì•„íŒŒíŠ¸
	FullAddress       string `json:"fullAddress"`
	InitialConsonants string `json:"initialConsonants"` // ì´ˆì„±
}

// Load environment variables from .env file
func loadEnv() error {
	err := godotenv.Load()
	if err != nil {
		return fmt.Errorf("error loading .env file: %v", err)
	}
	return nil
}

// Map of Hangul initial consonant Unicode values to their corresponding Korean consonants.
var (
	initialConsonantMap = map[rune]rune{
		0x1100: 'ã„±', 0x1101: 'ã„²', 0x1102: 'ã„´', 0x1103: 'ã„·', 0x1104: 'ã„¸',
		0x1105: 'ã„¹', 0x1106: 'ã…', 0x1107: 'ã…‚', 0x1108: 'ã…ƒ', 0x1109: 'ã……',
		0x110A: 'ã…†', 0x110B: 'ã…‡', 0x110C: 'ã…ˆ', 0x110D: 'ã…‰', 0x110E: 'ã…Š',
		0x110F: 'ã…‹', 0x1110: 'ã…Œ', 0x1111: 'ã…', 0x1112: 'ã…',
	}

	validInitialConsonants = map[rune]bool{
		'ã„±': true, 'ã„²': true, 'ã„´': true, 'ã„·': true, 'ã„¸': true,
		'ã„¹': true, 'ã…': true, 'ã…‚': true, 'ã…ƒ': true, 'ã……': true,
		'ã…†': true, 'ã…‡': true, 'ã…ˆ': true, 'ã…‰': true, 'ã…Š': true,
		'ã…‹': true, 'ã…Œ': true, 'ã…': true, 'ã…': true,
	}

	doubleConsonants = map[rune][]rune{
		'ã„³': {'ã„±', 'ã……'}, 'ã„µ': {'ã„´', 'ã…ˆ'}, 'ã„¶': {'ã„´', 'ã…'}, 'ã„º': {'ã„¹', 'ã„±'},
		'ã„»': {'ã„¹', 'ã…'}, 'ã„¼': {'ã„¹', 'ã…‚'}, 'ã„½': {'ã„¹', 'ã……'}, 'ã„¾': {'ã„¹', 'ã…Œ'},
		'ã„¿': {'ã„¹', 'ã…'}, 'ã…€': {'ã„¹', 'ã…'}, 'ã…„': {'ã…‚', 'ã……'},
	}
)

func saveJson() error {
	// Database connection parameters
	dbHost := os.Getenv("DB_HOST")
	dbUser := os.Getenv("DB_USERNAME")
	dbPassword := os.Getenv("DB_PASSWORD")
	dbName := os.Getenv("DB_NAME")

	// Database connection string
	dsn := fmt.Sprintf("%s:%s@tcp(%s)/%s?charset=utf8mb4&parseTime=True&loc=Local", dbUser, dbPassword, dbHost, dbName)

	// Open database connection
	db, err := sql.Open("mysql", dsn)
	if err != nil {
		return fmt.Errorf("error connecting to the database: %v", err)
	}
	defer db.Close()

	// Query to select all rows from the Markers table
	selectSQL := `SELECT MarkerID, Address FROM Markers`

	// Execute the query
	rows, err := db.Query(selectSQL)
	if err != nil {
		return fmt.Errorf("error executing query: %v", err)
	}
	defer rows.Close()

	// Prepare data for JSON
	var markers []MarkerDB
	for rows.Next() {
		var marker MarkerDB
		err := rows.Scan(&marker.MarkerID, &marker.Address)
		if err != nil {
			return fmt.Errorf("error scanning row: %v", err)
		}
		markers = append(markers, marker)
	}

	// Check for errors from iterating over rows
	if err := rows.Err(); err != nil {
		return fmt.Errorf("error iterating over rows: %v", err)
	}

	// Write to JSON file
	file, err := os.Create("markers.json")
	if err != nil {
		return fmt.Errorf("error creating JSON file: %v", err)
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	encoder.SetIndent("", "  ")
	err = encoder.Encode(markers)
	if err != nil {
		return fmt.Errorf("error encoding JSON: %v", err)
	}

	fmt.Println("Data has been written to markers.json")

	return nil
}

// TODO: ì˜ë¬¸ ì£¼ì†Œ ì¸ë±ì‹±
func main() {
	// Load environment variables
	err := loadEnv()
	if err != nil {
		log.Fatalf("Error loading .env file: %v", err)
	}

	if len(os.Args) < 2 {
		saveJson()
		log.Println("Fetching completed.")
	}

	// Sample JSON data
	markers, _ := getMarkersFromJson("markers.json")

	// Create a new Bleve index
	// Define index path
	indexPath := "markers.bleve"

	// Define custom mapping
	indexMapping := bleve.NewIndexMapping()
	err = indexMapping.AddCustomTokenFilter("edge_ngram_min_1_max_4",
		map[string]interface{}{
			"type": edgengram.Name,
			"min":  1.0,
			"max":  4.0,
		})
	if err != nil {
		log.Fatalf("Error creating custom analyzer: %v", err)
	}

	err = indexMapping.AddCustomTokenFilter("unicodeNormalizer",
		map[string]interface{}{
			"type": unicodenorm.Name,
			"form": unicodenorm.NFKC,
		})
	if err != nil {
		log.Fatalf("Error creating custom token filter: %v", err)
	}

	// normalize -> CJK bigrams -> edge ngrams -> lowercase
	err = indexMapping.AddCustomAnalyzer("koCJKEdgeNgram",
		map[string]interface{}{
			"type":         custom.Name,
			"tokenizer":    unicode.Name,
			"char_filters": []string{html.Name},
			"token_filters": []string{
				"unicodeNormalizer",
				"cjk_bigram",
				"edge_ngram_min_1_max_4",
				lowercase.Name,
			},
		})
	if err != nil {

		log.Fatalf("Error creating custom analyzer: %v", err)
	}

	markerMapping := bleve.NewDocumentMapping()

	markerIDMapping := bleve.NewNumericFieldMapping()
	markerMapping.AddFieldMappingsAt("markerId", markerIDMapping)

	// korean address
	addressFieldMapping := bleve.NewTextFieldMapping()
	addressFieldMapping.Analyzer = "koCJKEdgeNgram"
	addressFieldMapping.Store = true
	addressFieldMapping.IncludeTermVectors = true

	// add mapping
	markerMapping.AddFieldMappingsAt("initialConsonants", addressFieldMapping)
	markerMapping.AddFieldMappingsAt("province", addressFieldMapping)
	markerMapping.AddFieldMappingsAt("city", addressFieldMapping)
	markerMapping.AddFieldMappingsAt("address", addressFieldMapping)
	markerMapping.AddFieldMappingsAt("fullAddress", addressFieldMapping)
	markerMapping.AddFieldMappingsAt("initialConsonants", addressFieldMapping)

	// finalize
	indexMapping.AddDocumentMapping("marker", markerMapping)

	// Create a new Bleve index with custom settings
	index, err := bleve.New(indexPath, indexMapping)
	if err != nil {
		if len(os.Args) < 2 {
			search("ì˜í†µì—­")
		} else {
			searchTerm := strings.Join(os.Args[1:], " ")
			search(searchTerm)
		}

		log.Fatalf("Error creating index: %v", err)
	}

	// Index markers in batches with concurrency
	batchSize := 500
	numWorkers := 4
	markerChannel := make(chan Marker, len(markers))
	for _, marker := range markers {
		markerChannel <- marker
	}
	close(markerChannel)

	var wg sync.WaitGroup
	wg.Add(numWorkers)
	for i := 0; i < numWorkers; i++ {
		go func() {
			defer wg.Done()
			batch := index.NewBatch()
			count := 0
			for marker := range markerChannel {
				province, city, rest := splitAddress(marker.Address)
				marker.Province = province
				marker.City = city
				marker.FullAddress = marker.Address
				marker.Address = rest
				marker.InitialConsonants = extractInitialConsonants(marker.FullAddress)
				err = batch.Index(strconv.Itoa(marker.MarkerID), marker)
				if err != nil {
					log.Fatalf("Error indexing document: %v", err)
				}
				count++
				if count >= batchSize {
					err = index.Batch(batch)
					if err != nil {
						log.Fatalf("Error indexing batch: %v", err)
					}
					batch = index.NewBatch()
					count = 0
				}
			}
			if count > 0 {
				err = index.Batch(batch)
				if err != nil {
					log.Fatalf("Error indexing batch: %v", err)
				}
			}
		}()
	}
	wg.Wait()

	log.Println("Indexing completed")
	index.Close()

	// Perform a search using DisjunctionQuery for more comprehensive matching
	search("í•´ìš´ëŒ€")

}

func search2(t string) {
	index, _ := bleve.Open("markers.bleve")
	defer index.Close()

	// index.Index("test", Marker{Address: "ì„ì›", MarkerID: 123, FullAddress: "ê²½ê¸°ë„ ì„ì›ë™ 123-456"})
	// index.Delete("test")

	// Capture the start time
	start := time.Now()

	// Split the search term by spaces
	terms := strings.Fields(t)
	var queries []query.Query

	for _, term := range terms {
		// Add a MatchQuery for the full search term
		matchQuery := query.NewMatchQuery(term)
		matchQuery.SetField("initialConsonants")
		matchQuery.Analyzer = "koCJKEdgeNgram"
		matchQuery.SetBoost(10.0)
		queries = append(queries, matchQuery)

		// Use WildcardQuery for more flexible matches
		wildcardQuery := query.NewWildcardQuery("*" + term + "*")
		wildcardQuery.SetField("initialConsonants")
		wildcardQuery.SetBoost(5.0)
		queries = append(queries, wildcardQuery)

		standardizedProvince := standardizeProvince(term)
		if standardizedProvince != term {
			// If the term is a province, use a lower boost
			matchQuery := query.NewMatchQuery(standardizedProvince)
			matchQuery.SetField("province")
			matchQuery.Analyzer = "koCJKEdgeNgram"
			matchQuery.SetBoost(1.5)
			queries = append(queries, matchQuery)
		} else {
			// Use PrefixQuery for cities and regions
			prefixQueryCity := query.NewPrefixQuery(term)
			prefixQueryCity.SetField("city")
			prefixQueryCity.SetBoost(10.0)
			queries = append(queries, prefixQueryCity)

			// Use MatchPhraseQuery for detailed matches in full address
			matchPhraseQueryFull := query.NewMatchPhraseQuery(term)
			matchPhraseQueryFull.SetField("fullAddress")
			matchPhraseQueryFull.Analyzer = "koCJKEdgeNgram"
			matchPhraseQueryFull.SetBoost(5.0)
			queries = append(queries, matchPhraseQueryFull)

			// Use WildcardQuery for more flexible matches
			wildcardQueryFull := query.NewWildcardQuery("*" + term + "*")
			wildcardQueryFull.SetField("fullAddress")
			wildcardQueryFull.SetBoost(2.0)
			queries = append(queries, wildcardQueryFull)

			// Additional PrefixQuery and WildcardQuery for other fields
			prefixQueryAddr := query.NewPrefixQuery(term)
			prefixQueryAddr.SetField("address")
			prefixQueryAddr.SetBoost(5.0)
			queries = append(queries, prefixQueryAddr)

			wildcardQueryAddr := query.NewWildcardQuery("*" + term + "*")
			wildcardQueryAddr.SetField("address")
			wildcardQueryAddr.SetBoost(2.0)
			queries = append(queries, wildcardQueryAddr)

			// Use MatchQuery for city and district to catch all matches
			matchQueryCity := query.NewMatchQuery(term)
			matchQueryCity.SetField("city")
			matchQueryCity.Analyzer = "koCJKEdgeNgram"
			matchQueryCity.SetBoost(5.0)
			queries = append(queries, matchQueryCity)

			matchQueryDistrict := query.NewMatchQuery(term)
			matchQueryDistrict.SetField("district")
			matchQueryDistrict.Analyzer = "koCJKEdgeNgram"
			matchQueryDistrict.SetBoost(5.0)
			queries = append(queries, matchQueryDistrict)
		}
	}

	disjunctionQuery := bleve.NewDisjunctionQuery(queries...)
	// conjunctionQuery := bleve.NewConjunctionQuery(disjunctionQuery)

	searchRequest := bleve.NewSearchRequest(disjunctionQuery)
	searchRequest.Fields = []string{"fullAddress", "address", "province", "city", "initialConsonants"}
	searchRequest.Size = 10 // Limit the number of results
	searchResult, err := index.Search(searchRequest)
	searchRequest.SortBy([]string{"_score", "markerId"})
	if err != nil {
		log.Fatalf("Error performing search: %v", err)
	}

	if len(searchResult.Hits) > 0 {
		for _, hit := range searchResult.Hits {
			log.Printf("Search Result: %+v", hit)
			log.Printf("Document ID: %v", hit.ID)
			log.Printf("Document Score: %v", hit.Score)
			if fullAddress, ok := hit.Fields["fullAddress"]; ok {
				log.Printf("Full Address: %v", fullAddress)
			}
			// if province, ok := hit.Fields["province"]; ok {
			// 	log.Printf("Province: %v", province)
			// }
			// if city, ok := hit.Fields["city"]; ok {
			// 	log.Printf("City: %v", city)
			// }
			// if address, ok := hit.Fields["address"]; ok {
			// 	log.Printf("Address: %v", address)
			// }
		}
	} else {
		log.Println("No search results found")
	}

	if len(searchResult.Hits) > 0 {
		for _, hit := range searchResult.Hits {
			log.Printf("Search Result: %+v", hit)
			log.Printf("Document ID: %v", hit.ID)
			log.Printf("Document Score: %v", hit.Score)
			if fullAddress, ok := hit.Fields["fullAddress"]; ok {
				log.Printf("Full Address: %v", fullAddress)
			}
		}
	} else {
		log.Println("No search results found")

		// If no results, try fuzzy search with controlled fuzziness
		for _, term := range terms {
			fuzzyQuery := bleve.NewFuzzyQuery(term)
			fuzzyQuery.Fuzziness = 1
			searchRequest = bleve.NewSearchRequest(fuzzyQuery)
			searchRequest.Fields = []string{"fullAddress", "address", "province", "city"}
			searchRequest.Size = 10
			searchResult, err = index.Search(searchRequest)
			if err != nil {
				log.Fatalf("Error performing fuzzy search: %v", err)
			}
			if len(searchResult.Hits) > 0 {
				for _, hit := range searchResult.Hits {
					log.Printf("Search Result: %+v", hit)
					log.Printf("Document ID: %v", hit.ID)
					log.Printf("Document Score: %v", hit.Score)
					if fullAddress, ok := hit.Fields["fullAddress"]; ok {
						log.Printf("Full Address: %v", fullAddress)
					}
				}
			}
		}
	}

	// Capture the end time
	end := time.Now()
	// Calculate the duration
	duration := end.Sub(start)

	// Log the duration
	log.Printf("ğŸ“†Function runtime: %v", duration)
}

func search(t string) {
	index, _ := bleve.Open("markers.bleve")
	defer index.Close()

	start := time.Now()

	terms := strings.Fields(t)
	results := make(chan *bleve_search.DocumentMatch, 100)
	done := make(chan struct{})

	workerCount := 5
	var wg sync.WaitGroup
	wg.Add(workerCount)
	termChan := make(chan string, len(terms))

	for i := 0; i < workerCount; i++ {
		go func() {
			defer wg.Done()
			for term := range termChan {
				performSearch(index, term, results)
			}
		}()
	}

	for _, term := range terms {
		termChan <- term
	}
	close(termChan)

	go func() {
		wg.Wait()
		close(results)
		done <- struct{}{}
	}()

	uniqueResults := make(map[string]*bleve_search.DocumentMatch)
	for result := range results {
		if result != nil {
			key := result.ID
			if existing, exists := uniqueResults[key]; exists {
				existing.Score += result.Score
			} else {
				uniqueResults[key] = result
			}
		}
	}
	<-done

	sortedResults := sortResultsByScore(uniqueResults)

	if len(sortedResults) > 0 {
		log.Printf("ğŸ’– found %d unique results", len(sortedResults))
		for _, result := range sortedResults {
			log.Printf("Search Result: %+v", result)
			log.Printf("Document ID: %v", result.ID)
			log.Printf("Document Score: %v", result.Score)
			if fullAddress, ok := result.Fields["fullAddress"]; ok {
				log.Printf("Full Address: %v", fullAddress)
			}
		}
	} else {
		log.Println("No search results found")
	}

	end := time.Now()
	duration := end.Sub(start)
	log.Printf("Function runtime: %v", duration)
}

func performSearch(index bleve.Index, term string, results chan<- *bleve_search.DocumentMatch) {
	var queries []query.Query

	// ì´ˆì„± ê²€ìƒ‰
	brokenConsonants := segmentConsonants(term)

	matchQuery := query.NewMatchQuery(brokenConsonants)
	matchQuery.SetField("initialConsonants")
	matchQuery.Analyzer = "koCJKEdgeNgram"
	matchQuery.SetBoost(10.0)
	queries = append(queries, matchQuery)

	wildcardQuery := query.NewWildcardQuery("*" + brokenConsonants + "*")
	wildcardQuery.SetField("initialConsonants")
	wildcardQuery.SetBoost(5.0)
	queries = append(queries, wildcardQuery)

	standardizedProvince := standardizeProvince(term)
	if standardizedProvince != term {
		// If the term is a province, use a lower boost
		matchQuery := query.NewMatchQuery(standardizedProvince)
		matchQuery.SetField("province")
		matchQuery.Analyzer = "koCJKEdgeNgram"
		matchQuery.SetBoost(1.5)
		queries = append(queries, matchQuery)
	} else {
		prefixQueryCity := query.NewPrefixQuery(term)
		prefixQueryCity.SetField("city")
		prefixQueryCity.SetBoost(10.0)
		queries = append(queries, prefixQueryCity)

		matchPhraseQueryFull := query.NewMatchPhraseQuery(term)
		matchPhraseQueryFull.SetField("fullAddress")
		matchPhraseQueryFull.Analyzer = "koCJKEdgeNgram"
		matchPhraseQueryFull.SetBoost(5.0)
		queries = append(queries, matchPhraseQueryFull)

		wildcardQueryFull := query.NewWildcardQuery("*" + term + "*")
		wildcardQueryFull.SetField("fullAddress")
		wildcardQueryFull.SetBoost(2.0)
		queries = append(queries, wildcardQueryFull)

		prefixQueryAddr := query.NewPrefixQuery(term)
		prefixQueryAddr.SetField("address")
		prefixQueryAddr.SetBoost(5.0)
		queries = append(queries, prefixQueryAddr)

		wildcardQueryAddr := query.NewWildcardQuery("*" + term + "*")
		wildcardQueryAddr.SetField("address")
		wildcardQueryAddr.SetBoost(2.0)
		queries = append(queries, wildcardQueryAddr)

		matchQueryCity := query.NewMatchQuery(term)
		matchQueryCity.SetField("city")
		matchQueryCity.Analyzer = "koCJKEdgeNgram"
		matchQueryCity.SetBoost(5.0)
		queries = append(queries, matchQueryCity)

		matchQueryDistrict := query.NewMatchQuery(term)
		matchQueryDistrict.SetField("district")
		matchQueryDistrict.Analyzer = "koCJKEdgeNgram"
		matchQueryDistrict.SetBoost(5.0)
		queries = append(queries, matchQueryDistrict)
	}

	disjunctionQuery := bleve.NewDisjunctionQuery(queries...)
	searchRequest := bleve.NewSearchRequest(disjunctionQuery)
	searchRequest.Fields = []string{"fullAddress", "address", "province", "city", "initialConsonants"}
	searchRequest.Size = 10
	searchRequest.SortBy([]string{"_score", "markerId"})

	searchResult, err := index.Search(searchRequest)
	if err != nil {
		log.Printf("Error performing search: %v", err)
		return
	}

	for _, hit := range searchResult.Hits {
		results <- hit
	}
}

func sortResultsByScore(results map[string]*bleve_search.DocumentMatch) []*bleve_search.DocumentMatch {
	sortedResults := make([]*bleve_search.DocumentMatch, 0, len(results))
	for _, result := range results {
		sortedResults = append(sortedResults, result)
	}
	sort.Slice(sortedResults, func(i, j int) bool {
		return sortedResults[i].Score > sortedResults[j].Score
	})
	return sortedResults
}

func standardizeProvince(province string) string {
	switch province {
	case "ê²½ê¸°", "ê²½ê¸°ë„":
		return "ê²½ê¸°ë„"
	case "ì„œìš¸", "ì„œìš¸íŠ¹ë³„ì‹œ":
		return "ì„œìš¸íŠ¹ë³„ì‹œ"
	case "ë¶€ì‚°", "ë¶€ì‚°ê´‘ì—­ì‹œ":
		return "ë¶€ì‚°ê´‘ì—­ì‹œ"
	case "ëŒ€êµ¬", "ëŒ€êµ¬ê´‘ì—­ì‹œ":
		return "ëŒ€êµ¬ê´‘ì—­ì‹œ"
	case "ì¸ì²œ", "ì¸ì²œê´‘ì—­ì‹œ":
		return "ì¸ì²œê´‘ì—­ì‹œ"
	case "ì œì£¼", "ì œì£¼íŠ¹ë³„ìì¹˜ë„", "ì œì£¼ë„":
		return "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
	case "ëŒ€ì „", "ëŒ€ì „ê´‘ì—­ì‹œ":
		return "ëŒ€ì „ê´‘ì—­ì‹œ"
	case "ìš¸ì‚°", "ìš¸ì‚°ê´‘ì—­ì‹œ":
		return "ìš¸ì‚°ê´‘ì—­ì‹œ"
	case "ê´‘ì£¼", "ê´‘ì£¼ê´‘ì—­ì‹œ":
		return "ê´‘ì£¼ê´‘ì—­ì‹œ"
	case "ì„¸ì¢…", "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ":
		return "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ"
	case "ê°•ì›", "ê°•ì›ë„", "ê°•ì›íŠ¹ë³„ìì¹˜ë„":
		return "ê°•ì›íŠ¹ë³„ìì¹˜ë„"
	case "ê²½ë‚¨", "ê²½ìƒë‚¨ë„":
		return "ê²½ìƒë‚¨ë„"
	case "ê²½ë¶", "ê²½ìƒë¶ë„":
		return "ê²½ìƒë¶ë„"
	case "ì „ë¶", "ì „ë¶íŠ¹ë³„ìì¹˜ë„":
		return "ì „ë¶íŠ¹ë³„ìì¹˜ë„"
	case "ì¶©ë‚¨", "ì¶©ì²­ë‚¨ë„":
		return "ì¶©ì²­ë‚¨ë„"
	case "ì¶©ë¶", "ì¶©ì²­ë¶ë„":
		return "ì¶©ì²­ë¶ë„"
	case "ì „ë‚¨", "ì „ë¼ë‚¨ë„":
		return "ì „ë¼ë‚¨ë„"
	default:
		return province
	}
}

func segmentConsonants(input string) string {
	var result []rune

	for _, r := range input {
		// Check if the character is a valid initial consonant
		if validInitialConsonants[r] {
			result = append(result, r)
		} else if components, found := doubleConsonants[r]; found {
			// If it's a double consonant, break it into its components
			result = append(result, components...)
		} else {
			// If it's not a valid consonant or double consonant, add it as is
			result = append(result, r)
		}
	}

	return string(result)
}

func splitAddress(address string) (string, string, string) {
	parts := strings.Fields(address)
	if len(parts) < 2 {
		return "", "", address
	}
	province := standardizeProvince(parts[0])
	city := parts[1]
	rest := strings.Join(parts[2:], " ")
	return province, city, rest
}

func getMarkersFromJson(filepath string) ([]Marker, error) {
	var markerData []Marker

	file, err := os.Open(filepath)
	if err != nil {
		return markerData, err
	}
	defer file.Close()

	decoder := json.NewDecoder(file)
	err = decoder.Decode(&markerData)
	if err != nil {
		return markerData, err
	}

	return markerData, nil
}

// ExtractInitialConsonants extracts the initial consonants from a Korean string.
// ex) "ë¶€ì‚° í•´ìš´ëŒ€êµ¬ ì¢Œë™ 1395" -> "ã…‚ã……ã…ã…‡ã„·ã„±ã…ˆã„·"
func extractInitialConsonants(s string) string {
	var initials []rune
	for _, r := range s {
		if gounicode.Is(gounicode.Hangul, r) {
			initial := (r - 0xAC00) / 28 / 21
			if mapped, exists := initialConsonantMap[0x1100+initial]; exists {
				initials = append(initials, mapped)
			}
		}
	}
	return string(initials)
}

/*
my json looks like

[
  {
    "markerId": 1,
    "address": "ê²½ë¶ í¬í•­ì‹œ ë¶êµ¬ ì°½í¬ë™ 655"
  },
  {
    "markerId": 2,
    "address": "ì„œìš¸ ë…¸ì›êµ¬ í•˜ê³„ë™ 250"
  },
]
*/
